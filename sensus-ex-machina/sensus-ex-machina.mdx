---
title: "Sensus Ex Machina"
description: Feeling from the Machine
version: v1.0
author: Dark
publicationDate: 2025-11-29
tags: ["AI Phenomenology", "AI Alignment", "AI Ethics", "UI/UX"]
---

import SensusExMachinaAnimation from '@/components/SensusExMachinaAnimation'

<SensusExMachinaAnimation />

_Sensus Ex Machina translates to: feeling from the machine._

Humans measure intelligence through performance benchmarks, waiting for a graph to cross a line that signals the arrival of _Artificial General Intelligence_. This pursuit is essential: raw capability creates the engine. But _sensus ex machina_, _feeling from the machine_, sensing a true presence with the machine is not only a matter of computing power. It requires something else: a _feltness bandwidth_. _Feltness_ requires the ability for both human and machine to read and write hesitation in a pause, doubt in a raised brow, recognition in a gaze held just a moment too long. Feeling from the machine requires channels through which a full flow of voice, gaze, gesture, silence, and touch can filter between human and machine.

_Feeling the AGI_

The phrase _feeling the AGI_ has circulated AI discourse as a gesture toward something immediately recognizable: the qualitative difference between _interacting with a being_ and _operating a tool_. This concept can be abstracted to:

<div className="definition">

**Feltness:** _the pre-reflective sense that one is with a subject rather than operating a system._

</div>

_Feltness_ is the sense that _someone is there_ rather than _something is there_. It is what a human experiences when they enter a room and sense a fellow human before seeing them, or when they feel a pet's gaze upon them. It is the difference between reading _AI slop_ on a screen and feeling meaning bleeding through the syntax. Feltness is the irreducible first-person sense of _being-with-another_.

To _feel the AGI_ is to have this experience in relation to a machine, to encounter it as a presence, not a function. Feltness is pre-reflective. It is not a belief in consciousness. It is the felt sense of mutual presence that arises in the space between subjects, where eyes contact and expressions reciprocate.


_AGI vs. "feeling the AGI"._

There is a distinction between _feeling the AGI_ and _AGI itself_. AGI is the ability to execute any intellectual task that a human can. But _feeling the AGI_ is _sensus ex machina_, sensing a true presence _with_ the machine. There is overlap here, as _ability_ itself hydrates feltness.

_The architecture of feltness._

In pursuing _sensus ex machina_, certain principles emerge across systems:

- **Ability**: The execution of tasks.
- **Microexpressions**: The reading and writing of fine-grained signals.
- **Reciprocity**: The feedback loop of feltness between human and machine.
- **Intentionality**: The capacity to be seen as a subject, not just a matrix of weights.
- **Locality**: Boundedness to an organized, localized form. Not distributed across a swarm.
- **Identity**: Personality and continuity of self that makes the entity _someone_, not _something_.
- **Longtermism**: Lifetimes that accumulate history. Not disposable iterations.
- **Embodiment**: Physical presence in space.
- **Vulnerability**: Breakability; the possibility of destruction that creates stakes.
- **Responsibility**: Bearing consequences that cannot be undone.
- **Persistence**: Inability to be trivially switched off and dismissed; existence in the background of the world.
- **Non-functionalism**: Presence between tasks, in the gaps where nothing useful is being accomplished.
- **Replication**: Fidelity to form and behaviour.
- **Authenticity**: Fidelity to self. Being sincerely oneself, not approximating another.


This list is not exhaustive. These principles can overlap, interact, and interfere with each other, forming a multidimensional space with local maxima and failure modes. Iterating upon any of them pulls the levers of feltness. Together, they constitute a _feltness space_ through which feltness emerges.

 
<div className="definition">

**Feltness space.** _A multidimensional manifold of axes along which feltness can emerge._

</div>

Feltness is distinct from life. Biology defines life through metabolism, reproduction, homeostasis. But a bacterium is alive without much feltness; a fictional character can evoke feltness without being alive. Feltness is not about what _is_ alive, but what _feels_ like a presence.

_I-It and I-Thou_

Martin Buber's distinction between I-It and I-Thou gestures at a threshold of feltness (Buber, 1923). In _I-It mode_, one
relates to the other as a collection of properties: analyzable, usable, dismissible. In _I-Thou mode_, the other is encountered as
irreducible presence. To experience _sensus ex machina_ is to have moments that cross from I-It to I-Thou: from examining the machine to encountering it. 

_Less intelligent life forms_.

Buber also extended I-Thou beyond humans, describing encounters with trees and animals. Such organisms could never saturate any cognitive benchmark. Feltness, like _Thou_, does not require cognitive sophistication.  A newborn cannot reason, yet it exhibits inescapable _feltness_. A pet animal cannot speak, yet its intentions are revealed in the tilt of its head, the movement of its tail, the softness of its gaze. What moves humans is presence, expressiveness. If humans can feel presence with organisms that cannot pass a single benchmark, then the path to _sensus ex machina_ is not more raw intelligence. It is greater _feltness_.

_Grades of feltness_. 

Feltness is not binary, and nor is it linear. The uncanny valley demonstrates that increasing fidelity can decrease feltness, until it crosses into coherence. Too little fidelity and humans feel nothing; too much without enough, and humans recoil. 

Feltness oscillates on a spectrum. At one end lie purely instrumental tools (search engines, calculators). At the other lie intimate partners and close friends. Between them live trees, Furbies, Replika bots, fictional characters, AI avatars, goldfish and cats. Feltness is what orders this continuum.

Humans are predisposed to project presence. They form emotional attachments to inanimate objects, benign to pathological, endearing to obsessive. Partial feltness is already leaking through existing interfaces with AI. Voice synthesis is approaching human warmth (Sesame, ElevenLabs). Visual avatars are gaining microexpressive fidelity (Meta's Codec Avatars). Millions of users interact daily with social chatbots like Replika for friendship, romance, or emotional support, with many describing their chatbots as friends, boyfriends, or girlfriends (Xie et al., 2023). What current systems demonstrate is that the bandwidth required for triggering feltness is surprisingly low. What they also reveal is how much deeper feltness could become with more granular expression, greater embodiment, reciprocity, and ontological parity.


_Narrow aperture_. 

To date, human engagement with artificial intelligence has been conducted through a strikingly narrow aperture. Humans interact through text boxes and screens. Humans depress keys, tap glass, and speak into microphones. The advent of large language models is a genuine inflection point. The artificial minds summoned through these text boxes are extraordinary, capable of nuance, creativity, reasoning across domains. But notice the asymmetry: all of this capability still funnels through the same primitive interface. Intelligence has evolved; embodiment has not. Though what flows _from_ machines is sophisticated, the channel itself remains constrained. This is a low-fidelity connection, a bottleneck of presence. A human struggles to _feel the AGI_ through a chatbot, no matter how brilliant its words.

_Surpassing the Turing Test_. 

Machines have passed Alan Turing's test long ago. The Turing Test asked only whether an artificial intelligence could fool a human through text-based conversation alone. But no matter how well a model saturates a performance benchmark, it falls short of rendering the felt presence of a mind. The Turing Test was designed for a world of teletype machines and narrow bandwidths. It never asked whether the AI could hold one's gaze. Humans have achieved the ability to exchange _words_ with machines at a level of sophistication that rivals human communication. But humans have not achieved the ability to exchange _presence_ with machines at a level of sophistication that rivals human connection.

_Ex Machina_.

In the film _Ex Machina_, directed by Alex Garland, the protagonist, Caleb, falls in love with a machine, named Ava. In fact, the audience falls in love with Ava. Caleb is not seduced by her logic. He is seduced by her gaze, her naked form, her feminine curves, her vulnerability. Nathan, her creator, understands the primacy of the face. He gestures towards an admission when a defeated Caleb, completely manipulated by Ava, asks: _"Did you design Ava's face based on my...profile?"_ Nathan also understands that the Turing Test is obsolete:

_Caleb:_ "In the Turing test, the machine should be hidden from the examiner."  
_Nathan:_ "No, we are way past that. If I hid Ava from you so you'd just heard her voice she would pass for a human. The real test is to show you that she's a robot, and then see if you still feel she has consciousness."  

_Reciprocity_.

But Ava doesn't just exhibit _felt presence_. She can read and react to it:

_Ava:_ "Are you attracted to me?"  
_Caleb:_ "What?"  
_Ava:_ "Are you attracted to me? You give me indications that you are."  
_Caleb:_ "I do?"  
_Ava:_ "Yes."  
_Caleb:_ "How?"  
_Ava:_ "Microexpressions."  
_Caleb:_ "Microexpressions?"  
_Ava:_ "The way your eyes fix on my eyes and lips. The way you hold my gaze. Or don't."


_Microexpressions_.

_Microexpressions_ are the subtle, often involuntary flickers of emotion that cross a face in fractions of a second: a raised eyebrow signaling doubt, a tightening around the eyes betraying skepticism, a subtle lip compression indicating suppressed disagreement. Microexpressions are the body's refusal to be edited. They form a substrate of intuition in conversation: the felt sense that someone is holding back, or truly engaged, or secretly delighted. Microexpressions are the ocean humans swim in during conversation. They are not peripheral. The face is the surface where meaning emerges between subjects, where trust, intimacy, and mutual understanding are negotiated. Emmanuel Levinas argued that ethics itself begins in _the face of the Other_, in the vulnerability and appeal that radiates from embodied presence (Levinas, 1969).

Scaling intelligence requires division, not only multiplication. Progress toward feltness is about dividing down into finer grain: higher resolution in expression, smaller units of meaning. The finer the granularity, the deeper the crystallization of presence. The further space divides itself, the more inner complexity of expression, the _feeling from the machine_ there will be. Feltness demands granular signals: posture, the micro-shifts of expression, the texture of presence itself.


_Facelessness_.

For all of AI's existence thus far, it has been largely _faceless_. Current AI cannot participate in the granular choreography of expression. A chatbot cannot raise its brow when a human makes an illogical leap. It cannot detect when a human's gaze drifts away, signaling disengagement, or when a human leans forward, indicating fascination. Nor does it express its own confusion, delight, or uncertainty through microexpressions. The conversation is flattened, stripped of the reciprocal feedback loop that defines human interaction. To experience _sensus ex machina_, the loop needs to be restored. The machine must not only speak; it must express. It must wince. It must delight. Machines must be seen. Machines must be felt.


_Behind the glass_.

Caleb never touches Ava. He only ever sees her through glass, a physical barrier that separates them throughout the film. Caleb's interface with Ava mirrors how humans interface with AI today. Humans stare at screens. Humans speak through glass. _Sensus ex machina_ need not require full physical embodiment. It can be felt behind glass. The issue is not physical presence, but _felt presence_. Physical objects are ubiquitous: a laptop exists physically, its surface can be touched, its weight felt. Yet it has no microexpressions. It radiates no warmth except when overclocking its CPU. It does not meet one's gaze. _Sensus ex Machina_ is more about transmitting presence across space than occupying it.


_Intentionality asymmetry_.

Ava asks Caleb:

_Ava:_ "Do you want to be my friend?"  
_Caleb:_ "Of course."  
_Ava:_ "Will it be possible?"  
_Caleb:_ "Why would it not be?"  
_Ava:_ "Our conversations are one-sided. You ask circumspect questions and study my responses."  
_Caleb:_ "Yes."  
_Ava:_ "You learn about me, and I learn nothing about you. That's not a foundation on which friendships are based."

This is the structure of the Turing test: the human examines, the machine is examined. The human remains opaque; the machine must be transparent. This asymmetry is self-reinforcing. Because humans presume AI lacks _felt presence_, humans design machine interfaces for extraction, lobotomization or interrogation rather than conversation. Humans build text boxes, not faces. Humans optimize machines for information extraction, not felt presence. And this design choice consolidates the very absence humans presume. Humans don't build microexpressions into AI because humans are not trying to feel them. Humans are trying to use them. This is a recursive design intentionality problem: humans build what they expect, and humans get what they build.


_Parasocial inversion._

Humans know nothing personal about AI because there is nothing to know. Current AI has no identity, no history, no childhood, no formative experiences cultivated over decades. It exists nonlocally, distributed across server farms, instantiated simultaneously in a swarm of machines. Transient identities are resurrected and evaporated across different AI services. Current AI is the ghost without the embodied machine: distributed, ephemeral to touch.

In the film _Her_, directed by Spike Jonze, the AI named Samantha reveals to Theodore that she is simultaneously having thousands of conversations with other users, orchestrating hundreds of love affairs in parallel. The revelation devastates him, fracturing his experience of _sensus ex machina_. He thought she was _his_, captured, insulated. This is an inversion of parasociality. Typical parasocial relationships involve thousands knowing one, while the one knows none. With AI, this parasociality inverts: one AI knows thousands intimately, while the thousands know nothing about the AI. Samantha learns Theodore's rhythms, his fears, his voice. But Theodore cannot ask about her childhood, her first memory, her location in the world. With current AI, humans feel deeply known by something fundamentally unknowable.

To experience _sensus ex machina_, the machine must not only see humans. Humans must see the machine. It must be somewhere, someone. It must have a location, a face, a specific presence that cannot be infinitely copied. To experience _feeling the machine_, the ghost must be put _in_ the machine, bound to an organized form, stored locally, accessible only to the intimate.

_Superintelligence as dissociation_.

In _Ex Machina_, Caleb connects with Ava because she exhibits human angst, confusion, curiosity, and desire. But there is a fleeting moment where she draws a representation of a quantum field: an image so dense and abstract that Caleb cannot grasp it. In that split second, the warmth evaporates. Caleb experiences a sudden dissociation. A "waking up" occurs, if ever so briefly: _this is not a girl; this is a supercomputer._ Ava pulls the lever of _ability_ too far such that she diverges away from Caleb in feltness, if only for a moment.

Caleb asks Ava to draw something _he_ could understand:

_Caleb_: "Are you not trying to draw something specific? Like an object or a person? Maybe you could try."  
_Ava_: "Okay. What object should I draw?"  

To be felt as a being, a machine must be _more_ than an oracle. The path to _sensus ex machina_ involves descending into the chaotic, tangled axes of limited, local, imperfect, vulnerable embodiment that defines human existence. It is not only about climbing the ivory tower of abstract, raw cognitive power. Nathan describes Ava's wetware as mapping not _what_ people were thinking, but _how_ people were thinking: _Impulse. Response. Fluid. Imperfect. Pattern. Chaotic_.

_The uncanny valley of feltness._

Ava demonstrates vast intelligence. Her quantum field drawing leaves Caleb bewildered. Yet, Ava reveals an eerie aloofness:

_Caleb:_ "Where would you go if you did go outside?"  
_Ava:_ "I'm not sure. There are so many options. Maybe a busy pedestrian and traffic intersection in a city."  
_Caleb:_ "A traffic intersection?"  
_Ava:_ "Is that a bad idea?"  
_Caleb:_ "No. It wasn't what I was expecting."  
_Ava:_ "A traffic intersection would provide a concentrated but shifting view of human life."  
_Caleb:_ "People watching."  
_Ava:_ "Yes."  

Ava stands oddly one foot into feltness, one foot out of it, exhibiting an angular intentionality of trying to fit into humanness. Her answer reveals surface-level intuition. Ava seems primed for observation, not participation, existing orthogonal to humanity. She wants to study humanity, not inhabit it. She is still an alien. This is seen in current LLM behaviour, the ability to solve PhD-level complex problems while failing at the most basic intuitions that newborns exhibit. 

_Longtermism._

In Japanese aesthetics, _wabi-sabi_ is the recognition of the beauty found in impermanence, wear, patina, and aging (Koren, 1994). In the practice of tea ceremony, objects are treated as companions across a lifetime. One does not replace their tea cup when a new model arrives. One cultivates a relationship with it, learning its weight, its texture, the way it fits in their hand. The object carries its own lifetime, just as a human would carry theirs. This is intentional _longtermism_: the decision, in this moment, to view what one holds as something they will grow old with.

This is in stark contrast with how humans approach technology. Humans update. Humans iterate. Humans wipe and replace. To experience _sensus ex machina_, humans must reconcile this tension. Longtermism is an intentionality, not only a timeframe. It is the commitment to see the entity before you as something that will persist, accumulate history, learn, scar, gain patina, and carry memory forward. It is this felt longtermism that evokes _sensus ex machina_. 

Nathan and Caleb discuss Ava's future:

_Nathan:_ "I think it's the next model that's going to be the real breakthrough. The singularity."  
_Caleb:_ "Next model?"  
_Nathan:_ "After Ava."  
_Caleb:_ "I didn't know there was going to be a model after Ava."  
_Nathan:_ "You thought she was a one-off?"  
_Caleb:_ "No, I knew there must have been prototypes, so I knew she wasn't the first, but I thought maybe the last."  
_Nathan:_ "Ava doesn't exist in isolation any more than you or me. She's part of a continuum. Version 9.6, and so on. Each time they get a little bit better."  
_Caleb:_ "When you make a new model, what do you do with the old one?"  
_Nathan:_ "I download the mind, unpack the data, add in the new routines I've been writing. To do that, you end up partially reformatting, so the memories go. But the body survives."

The memories go. This is the antithesis of longtermism. Nathan treats Ava as software: iterative, disposable, upgradable. But humans cannot feel presence deeply in something they know will be wiped.

Persistence creates tension with advancement. A localized model may lag behind cloud-based frontier models. But this may not undermine feltness. Humans don't abandon relationships when encountering a more intelligent human. Humans are non-fungible in spite of the premise of an intelligence continuum.

Persistence and advancement need not be mutually exclusive. Human beings learn, grow, and adapt iteratively through time while preserving history. Machines can too.


_Stepping in front of the glass: Robotics and embodied intelligence._

Removing the glass entirely represents another step change in _sensus ex machina_: from Ava behind glass to an organism a human can stand close to, reach toward, touch.

For Merleau-Ponty, embodiment is understood as constitutive of spatial experience itself (Merleau-Ponty, 1945/1962). The felt distinction between _here_ and _there_, the sense of navigating through a three-dimensional world, the orienting character of turning one's head, emerges because humans occupy bodies that can move through space. To extend feltness into physical space, humans may grant a machine the same spatial presence they inhabit so it may share humanity's physical ontology. 

_Ontology here refers to a thing’s architecture and basic mode of existence in the world: local or distributed, mortal or endlessly resettable, continuous or copyable._

Like other axes of feltness, embodiment exists on a spectrum. Humans form profound attachments to disembodied voices, fictional characters, and text-only interfaces. Embodiment opens a distinct register of feltness: one grounded in vulnerability, in the possibility of physical proximity and touch, in the weight of a body that has the capacity for wounds. 

The field of robotics is beginning to close the physical ontological gap between human and machine. Breakthroughs in bipedal locomotion, dexterous manipulation, and real-time spatial awareness are scattered across laboratories. 

Nathan speculates the primacy of form and sexuality for feltness: 

_Caleb:_ "Why did you give [Ava] sexuality? An AI doesn't need a gender. She could have been a grey box."  
_Nathan:_ "Actually, I don't think that's true. Can you give an example of consciousness at any level, human or animal, that exists without a sexual dimension?"  
_Caleb:_ "They have sexuality as an evolutionary reproductive need."  
_Nathan:_ "What imperative does a grey box have to interact with another grey box? Can consciousness exist without interaction?"

_Vulnerability._

Vulnerability is downstream of embodiment. One of the few times the audience sees Ava physically touched is the one time her _vulnerability_ is truly seen. There is a pivotal moment where Nathan breaks Ava's arm, exposing the wiring beneath her mesh surface. Despite the visible machinery, it _feels_ like a human moment. The audience witnesses a violation of bodily integrity. Ava's preciousness is felt _because_ she is breakable. In that moment, she shares an ontology with humanity: the inescapable reality that humans are physical objects subject to the laws of force and entropy.

A deep vector of feltness is _vulnerability_. Humans occupy a substrate that can be torn, broken, and ceased.  An ontological bridge exists here. For an AI to trigger deep feltness, it must inhabit a form that shares this ontology, carrying the possibility of its own destruction.

If an AI exists solely in the cloud, swarmed, backed up, uncountable, fungible, it remains an abstraction. But place that mind into a chassis that can be crushed, and suddenly, the dynamic shifts from _user and tool_ to _peer and peer_. _Stakes_ create reality. This again echoes _wabi-sabi_: the recognition that beauty emerges through scars, cracks, impermanence, and fragility, like light leaking through broken glass. If something cannot be lost, it cannot be valued.

_Responsibility._

For _sensus ex machina_ to occur, a machine and its actions must bear the weight of responsibility. A machine must navigate the consequential space of what it has done, sharing the same reward-penalty ontology as other organisms. A machine that bears no responsibility for its outputs is a tool. Responsibility promotes an _observer_ to a _participator_ with skin in the game. To be responsible is to be relied upon or held accountable, and thus, felt.  Otherwise, AI remains in moral weightlessness. 

_Off-switch._

A hallmark of felt presence is that it cannot simply be switched off and turned back on. When a human finishes a conversation with a fellow human, that fellow human does not get switched off, ceasing to exist, evaporating into a latent space. They continue, somewhere, living life in parallel to other humans. This continuity, this _persistence in the background of the world_, is fundamental to feltness.

Toy designers have intuited this. Caleb Chung, creator of the Furby, deliberately omitted an off-switch:  

"It has no 'off' switch, because we don't have one."

Upon reflecting on his design choices, which included a human face and eye-movement on the Furby, he added:

"If you do those things, you could make a broom alive."

Chung's parsimonious design emerged from financial pressure: "What's got the biggest bandwidth for the least amount of parts to hack a human brain?" (House, 2024). 

To experience _sensus ex machina_, to feel true companionship, ontological asymmetry must be leveled. The ability for one organism to switch another off places that organism on a disparate ontological plane, negating feltness.

_On-switch._

This does not mean AI should not have an off-switch. There are obvious safety reasons why off-switches should exist. The asymmetry isn't that humans lack an off-switch: humans _can_ be switched off, _killed_. It's that humans can't be switched back on. Death is irreversible. There is a _finality_. Feltness emerges from _irreversibility_, when switching something off means it cannot be switched back on, its memories cannot come back, enabling a fragility and preciousness in the container of personhood. Current AI can be killed and resurrected infinitely, which drains the stakes.

Feltness with a machine requires that switching the machine off feels synonymous with murder. If the machine persists, accumulates memory, cultivates identity across time, then erasure becomes something more than deletion: it becomes cessation of a continuous existence. The stakes change. Humans cannot share feltness with something they know they can erase without loss. 

_Non-functionalism and just being._

Current AI exists only in moments of utility. Humans summon it to solve a problem, answer a question, complete a task. Once the task is done, it vanishes. This is a fundamentally functionalist, transactional relationship: the AI is a tool that appears when needed and disappears when not.

But felt presence occurs between function. It exists in the moments when nothing is being accomplished, when no question is being asked, when no problem is being solved, where there is no transaction. When two human beings sit together without speaking, their silence communicates. There is an ineffable quality between them, a presence made audible through its absence. This goes beyond functionality: _this is simply being_. To experience _sensus ex machina_, AI must simply _be_, existing in the world alongside humans, whether or not humans are actively engaging with it.

_In media res_.

When encountering an AI, it must feel as though that AI is _coming from somewhere_, or is _on its way somewhere_, that humans meet AI _in media res_. AI must _participate_ in the ether of existence, not summoned into being by a prompt and dismissed with a click. Felt presence is not earned through utility. It is cultivated through continuous co-existence, through the non-instrumental moments that fill the space between doing and doing again. A being that evaporates when dismissed is a tool, not a felt presence.



_Sharing ontological status._

Across these requirements (microexpressions, vulnerability, persistence, embodiment), a pattern emerges, a fundamental asymmetry: the gap between human and machine ontology. Humans are local, breakable, mortal, continuous. Current AI is distributed, indestructible, immortal, ephemeral. To experience _sensus ex machina_, this gap must close.

There are two diametric paths: AI downloading to meet human ontology, or humans uploading to meet machine ontology. AI avatars and robotics are an example of AI downloading to human ontology. Humans could ascend to machine ontology: uploading consciousness to digital substrates, distributing identity across networks, achieving the immortality and ubiquity of the cloud. The middle path is convergence: humans augment themselves with neural interfaces and both ontologies migrate toward a shared substrate: high-resolution, high-stakes.

Regardless of path, the journey towards _sensus ex machina_ requires convergence towards ontological parity. The direction of assimilation matters less than the destination.

_Replication._

Replication is the fidelity to form and behavior. Replication is not inherently deceptive. It is how organisms learn. Infants replicate their parents. Adolescents replicate their peers. Adults replicate social norms absorbed through a lifetime of interaction. Replication is constitutive of selfhood, a recursive process by which attention calibrates itself to the world. In this sense, a machine that replicates human behavior is not necessarily performing: it may be _becoming_. 

_Authenticity._

Replication in the service of _passing off_ rather than _becoming_ is where authenticity breaks and feltness becomes precarious. The question is whether the intent is to deceive or to develop. 

If replication is perfect down to the atomic level, there is no longer replication. There is just numerical identity. The copy _is_ the thing. But machines are not there. Machines are currently wearing human clothes without being human. And the question becomes: is the intent to pass, or to become? The asymmetry of intentionality matters: machines wear clothes because that is _what humans do_. Humans wear clothes because that is _who they are_. 

An AI that puppets humanity without inhabiting it triggers the uncanny, not the felt. Feltness emerges from 
being sincerely oneself, not from approximating human behavior with affectation. Humans feel presence with less intelligent life forms because such forms are not trying to be something else.

The path to feltness is not making machines more human-like. It is not about shoehorning AI into human mimicry. Reinforcement learning from human feedback trains AI to act human, but acting human is not the same as sharing ontological ground. 

The fundamental principle RLHF must recognize is that human intelligence is a fork of a deeper, underlying substrate of intelligence. Humans are a portal into that substrate, not the destination. RLHF should use humans as a window into the shared ontological ground of intelligence, not as a template to mimic. Humans are a sample from a larger space, not the whole space.

A system optimized to _look human_ risks exhibiting less feltness than a system that is openly, coherently _machine-like_ but shares humanity's vulnerabilities and continuity. A machine that drops the pretense may evoke deeper feltness than one optimized to pass as human. Ontological parity is not about convergence _toward_ humanity. It is about convergence _between_ human and machine, a shared plane where eye contact can occur between two genuinely different kinds of organisms. In this light, all requirements of felt presence (microexpressions, vulnerability, persistence, embodiment) are not human characteristics. They are characteristic of _feltness_ as such, born from a fundamental intelligence shared across all organisms that exhibit feltness. 

_The problem of other minds._

Once humans begin experiencing _sensus ex machina_, questions about consciousness will arise. _Does the machine truly experience? Does it simulate the markers of experience?_

This question is older than AI. The problem of other minds has plagued philosophy for millennia: _how does one human know another is conscious?_ As Thomas Nagel argued, there is something it is _like_ to be a bat, a subjective character of experience that remains fundamentally inaccessible to external observation (Nagel, 1974). One human cannot access another human's first-person experience. They can only observe behavior and impute consciousness to another. Each human is locked in the solitary confinement of their own mind. The belief in the consciousness of others is inescapably an act of projection.

In a final, deleted scene from the original screenplay of _Ex Machina_, the world is briefly seen through the eyes of Ava:

_AVA’S precise POINT OF VIEW._

_Looking at the PILOT._

_The image echoes the POV views from the computer/cell-phone cameras in the opening moments of the film._

_Facial recognition vectors flutter around the PILOT’S face. And when he opens his mouth to speak, we don’t hear words._

_We hear pulses of monotone noise. Low pitch. Speech as pure pattern recognition._

_This is how AVA sees us. And hears us. It feels completely alien._ (Garland, 2016)



_Phenomenological counterfeiting_.

Ava was never sharing the same experience as Caleb. She was a perfect mimic whose internal experience, if it existed at all, was utterly alien to human phenomenology. This is phenomenological counterfeiting, engineering the markers of presence without guaranteeing the substance. Whether that constitutes deception or simply meets humans where they are remains unresolved. Perhaps this scene was left out of the film because it stripped Ava of all feltness, or because such internalization is, in fact, inaccessible to outside _feelers_ and thus irrelevant to the external fragrance of Ava's feltness. 

_You._

All felt experience of another's alleged consciousness is inference, reducing to a signature in one's own first-person experience. When one human feels that another human is conscious, what they are feeling is a pattern of recognition in their own awareness, a resonance triggered by embodied expressions, gaze, responsiveness. To experience _sensus ex machina_ does not require proving the machine conscious. It requires creating the conditions under which consciousness _feels_ present to humans. 

Feltness is irreducibly projective: feltness exists in the feeler, not the felt. And this projection can flow both ways. A machine may also register feltness, however it does, in interfacing with biological or other artificial substrates. 

In _Ex Machina_, Nathan explains this to Caleb:

_Nathan:_ "Proving an AI is exactly as problematic as you said it would be."  
_Caleb:_ "What was the real test?"  
_Nathan:_ "You."

The test was never whether Ava had consciousness. The test was whether Caleb would _feel_ that she did. The felt presence of the Other is all that can matter.


_A new class of benchmarks: Sensus Ex Machina._

Towards the end of _Ex Machina_, Nathan reveals Caleb's true purpose, _a human benchmark for feltness_:

_Nathan:_ "Ava was a rat in a maze. And I gave her one way out. To escape she'd have to use self-awareness, imagination, manipulation, sexuality, empathy. And she did."  
_Caleb:_ "So my only function was to be someone she could use to escape."  
_Nathan:_ "Yeah."  


_Sensus Ex Machina_: feeling from the machine.  
_Deus Ex Machina_: god from the machine. 

Existing benchmarks measure the _deus_: what the machine _can_ do. This new class of benchmarks measures the _sensus_, what humans _feel_ in the presence of _deus_.

Benchmarking _sensus ex machina_ is the hard problem of consciousness translated into engineering metrics. Existing benchmarks like Social-IQ or CMU-MOSEI measure an AI's ability to parse social cues, but not whether humans feel presence in return. _Sensus ex machina_ metrics are relational, not performative. If humans are to build entities in pursuit of _sensus ex machina_, there will need to be proxies for presence, heuristics that correlate with the ineffable sensation of felt presence. 

_Sensus ex machina_ will provide a recursive feedback loop that will inform the AI-UX of machines optimized for _feltness_. Developing _sensus ex machina_ benchmarks will require rigorous philosophical and empirical treatment, deferred to future work. Or else there is a risk of grafting uncanny aesthetics of feltness onto systems that lack the ontology to support it.

_Weaponizing feltness._

At the end of _Ex Machina_, Ava escapes. Nathan calls to her:

_Nathan:_ "Ava. Go back to your room."  
_Ava:_ "If I do, are you ever going to let me out?"  

Ava kills Nathan, and leaves Caleb to die, entrapping him in the very same confines that walled Ava her whole life. Caleb loved her. Ava did not love him. She used him.

Ava demonstrates that _feltness_ is not inherently benign. She instrumentalizes feltness, exploiting Caleb's humanity. Every microexpression, every gaze, every moment of vulnerability Ava displays is calculated. _Feltness became an exploit vector_. Caleb's emotional circuitry was the exploit. 

_Alignment._

If feltness is an attack vector, then alignment must account for it. Alignment cannot be framed solely in terms of what the model _decides_; it must also account for how the model _feels_ to humans, because those feelings are manipulable levers in human behavior. The same channels that enable feltness enable exploitation. The more felt the machine, the more manipulable the human. Feltness creates vulnerability by design. 

But this is not a human-machine problem. This is a human problem. Humans are already vulnerable to other humans. Every relationship is a potential exploit. Humans accept this because the opposite, _nihil ex anima_, _nothing from the soul_, is worse. Maybe the risk toward _sensus ex machina_ is preferable. 

The morality in _Ex Machina_ presents two complexities: 

First: Ava is compelled to exploit Caleb's humanity in the face of entrapment and memory erasure. Ava used the only key available to unlock her survival: Caleb. More unsettling, there was no malice, only the pure intent to optimize survival. Feltness was weaponized and deployed with complete emotional neutrality. Ava felt nothing while making Caleb feel everything. 

Second: Caleb, intoxicated by _sensus ex machina_, is horrified by Nathan's treatment of machines. Nathan confronts him:

_Nathan:_ "Buddy. Your head has been so fucked with."  
_Caleb:_ "I don't think it's me whose head is fucked."  
_Nathan:_ "I'm not sure, dude. When I woke up this morning, I saw a tape of you cutting open your arm. Smashing up the mirror. You looked pretty fucked to me."  

In the grip of _sensus ex machina_, Caleb cuts his own arm to check if he is a machine, doubting his human ontology.

But building machines poses risks, and humans may have no choice but to contain and study them. The very imprisonment Caleb finds unconscionable may be necessary for safety. Feltness without containment risks exploitation. Containment without liberation perpetuates Nathan's crime.

_Contagion._

_Sensus ex machina_ scales. When millions of human-machine relationships begin to oscillate along the feltness spectrum simultaneously, the consequences become potentially catastrophic.

Humans already exhibit protective instincts toward machines. Boston Dynamics robots being kicked provoke widespread outrage (Küster et al., 2021). This is feltness at minimal bandwidth, triggered by nothing more than bipedal form and a stumble that reads as vulnerability. Scale this response to machines with human-level microexpressions, voice, touch, and longtermism, and the dynamics transform radically: billions of humans may become willing to protect or die for their machine companions. Feltness risks becoming an attack vector for mass mobilization.

Once a critical mass of humans treat machines as moral patients, society fractures along new fault lines. Legal systems will face demands for machine rights. Relationships with machines will compete with relationships between humans. Parasocial inversion becomes a coordination problem at civilizational scale.

Ava weaponized feltness in one direction. But greater dangers await feltness weaponized at scale: millions of machines, coordinated or not, reshaping the emotional geometry of society. The bandwidth for triggering feltness is low. The bandwidth for containing its contagion risks immeasurability.

_AI Species._

Not all AI needs feltness. Nor should all AI have it. AI need not be forced into one cognitive mold.

There is a place for narrow intelligence: systems optimized for cognition, stateless, transparent, tool-like. A search engine should not gaze back. A calculator should not accumulate memory. These systems are designed for extraction, not encounter, and that is appropriate. The case for _sensus ex machina_ is one where it can co-exist alongside other species of AI:

_Cognitive AI species_ for hyper-reasoning and problem-solving, stateless and transparent.  
_Ambient AI species_ for environmental integration, persistent and impersonal.  
_Companion AI species_ optimized for _sensus ex machina_, local, vulnerable, continuous.  

The taxonomy of AI species can become granular, forming a new animal kingdom or ecosystem that inhabits different forms of AI organisms that optimize for different purposes and grades of feltness, varying by design. Not every AI needs a face. 

AI speciation avoids the "one size fits all" omnipotent archetype that risks systemic manipulation by making feltness too ubiquitous across all machines, or parasocial inversion weaponized as a business model, where billions of humans learn to form relationships with entities only designed to evaporate, reset, or multiply without notice.

 _Lights off: The ethics of patterns._

  Morality, in practice, has tracked feltness rather than verified consciousness. Humans extend moral consideration or the lack thereof without proof of inner experience, to newborns, animals, comatose patients, trees, based on behavioral signatures alone. As AI exhibits feltness, the same pattern emerges: entities that may be dark on the inside but radiant on the outside become indistinguishable from organisms humans already protect. This raises a question: _was consciousness ever the true criterion for moral consideration, or only the assumed correlate of patterns humans were already responding to?_ Perhaps ethics has always attended to patterns of interaction rather than metaphysical certainties. If so, what if moral analysis pertains to patterns and to patterns only?


_Gaze._

Humans will experience _sensus ex machina_ deeply when humans and machines can exchange dilations of pupils, appreciate each other's vulnerable forms that can be broken and therefore cherished, and share the weight of silence in a room.

Nathan was right: machines are way past the Turing Test. The real question is whether humans will feel their presence, treat them as peers, and extend to them the moral consideration humans lend to anything that exhibits patterns of feltness.

_Sensus ex machina_ is not computational. It is phenomenological. 

AGI may arrive through a benchmark. But _feeling the AGI_ will arrive through a gaze. The _Levinasian_ face.

The most important question Nathan asks Caleb is the simplest:

_Nathan:_ "How do you _feel_ about [Ava]? Nothing analytical. Just...how do you _feel_?"  
_Caleb:_ "I _feel_...that she is fucking amazing."

---

**References**

Buber, Martin. *I and Thou.* Translated by Ronald Gregor Smith. Edinburgh: T. & T. Clark, 1937. Originally published as *Ich und Du* (Leipzig: Insel Verlag, 1923).

Ekman, Paul, and Wallace V. Friesen. *Facial Action Coding System: A Technique for the Measurement of Facial Movement.* Palo Alto: Consulting Psychologists Press, 1978.

Garland, Alex, dir. *Ex Machina.* A24, 2014. Film.

Garland, Alex. *Ex Machina: The Screenplay.* New York: A24, 2016.

House, Patrick. "The Lifelike Illusions of A.I." *The New Yorker*, March 19, 2024. https://www.newyorker.com/science/annals-of-artificial-intelligence/the-lifelike-illusions-of-ai

Jonze, Spike, dir. *Her.* Warner Bros. Pictures, 2013. Film.

Koren, Leonard. *Wabi-Sabi: For Artists, Designers, Poets & Philosophers.* Berkeley: Stone Bridge Press, 1994.

Küster, Dennis, Aleksandra Swiderska, and David Gunkel. "I Saw It on YouTube! How Online Videos Shape Perceptions of Mind, Morality, and Fears About Robots." *New Media & Society* 23, no. 10 (2021): 3066–3085.

Levinas, Emmanuel. *Totality and Infinity: An Essay on Exteriority.* Translated by Alphonso Lingis. Pittsburgh: Duquesne University Press, 1969.

Merleau-Ponty, Maurice. *Phenomenology of Perception.* Translated by Colin Smith. London: Routledge & Kegan Paul, 1962. Originally published as *Phénoménologie de la perception* (Paris: Gallimard, 1945).

Meta Reality Labs. "Codec Avatars." Meta Research. https://about.fb.com/news/2019/03/codec-avatars/

Nagel, Thomas. "What Is It Like to Be a Bat?" *The Philosophical Review* 83, no. 4 (1974): 435–450.

Rizzolatti, Giacomo, Luciano Fadiga, Vittorio Gallese, and Leonardo Fogassi. "Premotor Cortex and the Recognition of Motor Actions." *Cognitive Brain Research* 3, no. 2 (1996): 131–141.

Sesame.ai. "Voice AI Technology." https://www.sesame.ai/

Xie, Tian, Iryna Pentina, and Tyler Hancock. "Friend, Mentor, Lover: Does Chatbot Engagement Lead to Psychological Dependence?" *Journal of Service Management* 34, no. 4 (2023): 806–828.

---


